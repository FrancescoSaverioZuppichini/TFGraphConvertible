{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize Class to TensorFlow Graph\n",
    "### Francesco Saverio Zuppichini\n",
    "Would it be cool to automatically bind class fields to tensorflow variables in a graph and restore them without manually get each variable back from the name and name them?\n",
    "\n",
    "Image you have a `Model` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.variable = None\n",
    "    def __call__(self):\n",
    "        self.variable = tf.Variable([1], name='variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, you first **build** your model, then you **train** it. After that, you want to **get** from the saved graph the old variable without rebuild the whole model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'variable:0' shape=(1,) dtype=int32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = Model()\n",
    "model() # now  model.variable exists\n",
    "print(model.variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imagine we have just trained our model and we want to store it. The usual pattern is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(EPOCHS):\n",
    "        # train\n",
    "        pass\n",
    "    saver.save(sess,'/tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you want to perform **inference**, aka get your stuff back, by loading the stored graph. In our case, we want the variable named `variable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        saver = tf.train.import_meta_graph(\"{}.meta\".format('/tmp/model.ckpt'))\n",
    "        saver.restore(sess, '/tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get back our `variable` from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"variable\"\n",
      "op: \"VariableV2\"\n",
      "attr {\n",
      "  key: \"container\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_INT32\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shared_name\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "variable = graph.get_operation_by_name('variable')\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, what if we want to use our `model` class again? If we try now to call `model.variable` we get None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model() # recreate the model\n",
    "print(model.variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One solution is to **build again** the whole model and restore the graph after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "<tf.Variable 'variable:0' shape=(1,) dtype=int32_ref>\n"
     ]
    }
   ],
   "source": [
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        model = Model()\n",
    "        model()\n",
    "        saver = tf.train.import_meta_graph(\"{}.meta\".format('/tmp/model.ckpt'))\n",
    "        saver.restore(sess, '/tmp/model.ckpt')\n",
    "        print(model.variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can already see that is a big waste of time.  We can bind `model.variable` directly to the correct graph node by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"variable\"\n",
      "op: \"VariableV2\"\n",
      "attr {\n",
      "  key: \"container\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_INT32\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shared_name\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.variable  = graph.get_operation_by_name('variable')\n",
    "print(model.variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now image we have a very big model with nested variables. In order to correct restore each variable pointer in the model you need to:\n",
    "\n",
    "* name each variable\n",
    "* get the variables back from the graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would it be cool if we can automatically retrieve all the variables setted as a field in the Model class? \n",
    "\n",
    "## TFGraphConvertible\n",
    "\n",
    "I have created a class, called `TFGraphConvertible`. You can use the `TFGraphConvertible` to automatically **serialize** and **deserialize**\" a class.\n",
    "\n",
    "Let's recreate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TFGraphConvertible import TFGraphConvertible\n",
    "class Model(TFGraphConvertible):\n",
    "    def __init__(self):\n",
    "        self.variable = None\n",
    "    def __call__(self):\n",
    "        self.variable = tf.Variable([1], name='variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It exposes two methods: `to_graph` and `from_graph` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize - to_graph\n",
    "In order to **serialize a class** you can call the **to_graph** method that creates a dictionary of field names -> tensorflow variables name. You need to pass a `fields` arguments, a dictionary of what field we want to serialize. In our case, we can just pass all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'to_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2d58ff8f1b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mserialized_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'to_graph'"
     ]
    }
   ],
   "source": [
    "serialized_model = model.to_graph(model.__dict__)\n",
    "print(serialized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will create a dictionary with all the fields as keys  and the corresponding tensorflow variables name as values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deserialize - from_graph\n",
    " In order to **deserialize a class** you can call the **from_graph** method that takes the previous created dictionary and bind each class fields to the correct tensorflow variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model() # simulate an empty model\n",
    "print(model.variable)\n",
    "model.from_graph(serialized_model, tf.get_default_graph())\n",
    "model.variable # now it exists again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you have your `model` back!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a more interesting example! We are going to train/restore a model for the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(Model):\n",
    "\n",
    "    def __call__(self, x, y, lr=0.001):\n",
    "        self.x = tf.cast(x, tf.float32)\n",
    "        self.x = tf.expand_dims(self.x, axis=-1)  # add grey channel\n",
    "\n",
    "        self.lr = lr\n",
    "\n",
    "        self.y = tf.one_hot(y, N_CLASSES, dtype=tf.float32)\n",
    "\n",
    "        out = tf.layers.Conv2D(filters=32, kernel_size=5, activation=tf.nn.relu, padding=\"same\", )(self.x)\n",
    "        out = tf.layers.MaxPooling2D(2, strides=2)(out)\n",
    "        out = tf.layers.Dropout(0.2)(out)\n",
    "        out = tf.layers.Conv2D(filters=64, kernel_size=5, activation=tf.nn.relu, padding=\"same\", )(out)\n",
    "        out = tf.layers.MaxPooling2D(2, strides=2)(out)\n",
    "        out = tf.layers.Dropout(0.2)(out)\n",
    "        out = tf.layers.flatten(out)\n",
    "        out = tf.layers.Dense(units=512, activation=tf.nn.relu)(out)\n",
    "        out = tf.layers.Dropout(0.2)(out)\n",
    "        self.forward_raw = tf.layers.Dense(units=N_CLASSES)(out)\n",
    "        forward = tf.nn.softmax(out)\n",
    "        self.accuracy = tf.reduce_mean(\n",
    "            tf.cast(tf.equal(tf.argmax(self.forward_raw, -1), tf.argmax(self.y, -1)), tf.float32))\n",
    "        \n",
    "        self.loss = self.get_loss()\n",
    "        self.train_step = self.get_train()\n",
    "        \n",
    "        return forward\n",
    "\n",
    "    def get_loss(self):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.y, logits=self.forward_raw))\n",
    "        return loss\n",
    "\n",
    "    def get_train(self):\n",
    "        return tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "\n",
    "mnist_model = MNISTModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "N_CLASSES = 10\n",
    "\n",
    "train, test = mnist.load_data()\n",
    "\n",
    "x_, y_ = tf.placeholder(tf.float32, shape=[None, 28, 28]), tf.placeholder(tf.uint8, shape=[None])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_, y_)).batch(64).shuffle(10000).repeat()\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_, y_)).batch(64).repeat()\n",
    "\n",
    "iter = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                       train_dataset.output_shapes)\n",
    "x, y = iter.get_next(name='iter_next')\n",
    "\n",
    "train_init_op = iter.make_initializer(train_dataset)\n",
    "test_init_op = iter.make_initializer(test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    mnist_model(x, y) # build the model\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(train_init_op, feed_dict={x_: train[0], y_: train[1]})\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    for i in range(150):\n",
    "        acc, _ = sess.run([mnist_model.accuracy, mnist_model.train_step])\n",
    "        if i % 15 == 0:\n",
    "            print(acc)\n",
    "            saver.save(sess,'/tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Let's store the serialized model in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_model = mnist_model.to_graph(mnist_model.__dict__)\n",
    "print(serialized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we reset the graph and recreat the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "mnist_model = MNISTModel()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        saver = tf.train.import_meta_graph(\"{}.meta\".format('/tmp/model.ckpt'))\n",
    "        saver.restore(sess, '/tmp/model.ckpt')\n",
    "        graph = tf.get_default_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, our variables in the `mnist_model` do not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recreate them by calling the `from_graph` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model.from_graph(serialized_model, tf.get_default_graph())\n",
    "mnist_model.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `mnist_model` is ready  to go, let's see the accuracy on a bacth of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(\"{}.meta\".format('/tmp/model.ckpt'))\n",
    "    saver.restore(sess, '/tmp/model.ckpt')\n",
    "    graph = tf.get_default_graph()\n",
    "    x, y = graph.get_tensor_by_name('iter_next:0'), graph.get_tensor_by_name('iter_next:1')\n",
    "    print(sess.run(mnist_model.accuracy, feed_dict={x: test[0][0:64], y: test[1][0:64]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "With this tutorial we have seen how to serialize a class and bind each field back to the correct tensor in the tensorflow graph. Be awere that you can store the `serialized_model` in `.json` format and load it directly where you need. In this way, you can directly create your model by using Object Oriented Programming and retrieve all the variales inside them without having to rebuild them.\n",
    "\n",
    "Thank you for reading\n",
    "\n",
    "Francesco Saverio Zuppichini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
